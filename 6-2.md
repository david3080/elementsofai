# 6-2 AIの社会的意味
本講座のごく初期に、今日および明日の社会におけるAIの重要性について簡単に議論しましたが、その時点では、議論を具体的な用語に基づかせるための技術的概念や手法を十分に紹介していなかったため、限られた範囲でしか議論することが出来ませんでした。

AIの基本概念の理解が深まった今、すでに現在のAIが内包する意味について、合理的な議論に参加できる立場にあります。

## 1. アルゴリズムによる偏り
![男と女](./6_4-man%26woman.svg)

AI、特に機械学習は、多くの分野で重要な意思決定に利用されています。このことから、アルゴリズム・バイアスという概念が浮かび上がってきます。どういうことかというと、就職活動や銀行融資などの意思決定をする際に、民族や性別などによって差別する傾向が埋め込まれていることです。

> **Note** 繰り返しになるがすべてはデータである
>
>アルゴリズムによるバイアスの主な原因は、データにおける人間のバイアスにあります。例えば、求職者のフィルタリングツールが人間の判断に基づいて学習された場合、機械学習アルゴリズムは女性や特定の民族的背景を持つ人を差別するよう学習する可能性があります。これは、民族や性別をデータから除外しても、応募者の名前や住所の情報をアルゴリズムが利用するために起こる可能性があることに注意してください。アルゴリズムによるバイアスは、学術研究者が考えた仮定の脅威ではありません。今日、すでに人々に影響を及ぼしている現実の現象なのです。

### オンライン広告

Googleのようなオンライン広告主は、男性に比べて女性ユーザーには低賃金の求人広告を表示する傾向があることが指摘されています。同様に、アフリカ系アメリカ人のような名前で検索すると、犯罪歴にアクセスするためのツールの広告が表示されることがありますが、これは他の方法では起こりにくいことです。

### ソーシャルネットワーク

ソーシャルネットワークは、基本的に他のユーザーのクリック数に基づいてコンテンツを推薦するため、たとえそれが元々非常に小さなものであったとしても、既存のバイアスを拡大させることにつながりやすいです。例えば、LinkedInで女性のファーストネームを持つプロフェッショナルを検索する際「Andrea」と検索すると「Andrewのことですか」と実際に類似した男性の名前を意味しているかどうかをユーザーに尋ねることが観察されています。「Andrea」のプロフィールを興味本位でクリックする人がいれば、その後の検索で「Andrew」がより上位に表示されるようになるのです。

他にも多くの事例がありますし、皆さんもニュースなどでご覧になったことがあるのではないでしょうか。ルールベースのシステムではなく、AIや機械学習を使用する際の主な問題は、その透明性の低さです。これは、アルゴリズムやデータが企業秘密であるため、企業が一般に公開する可能性が低いことが一因となっています。また、仮に公開したとしても、差別的な判断につながるアルゴリズムの部分やデータの要素を特定することは困難な場合が多いです。

> **Note** 規制による透明化？
>
>透明化に向けた大きな一歩となるのが、EUの一般データ保護規則（GDPR）です。この規則では、EU内に居住する、あるいはEUに顧客を持つすべての企業に対して、以下のことを義務付けています。
> - 要求に応じて個人について収集したデータを開示すること（アクセス権）
> - 要求に応じて他の義務を果たすために必要でないデータを削除すること（忘れる権利）
> - 顧客データに実施されたデータ処理について説明を行うこと（説明義務）

最後のポイントは、言い換えれば、FacebookやGoogleなどの企業が、少なくともヨーロッパのユーザーにサービスを提供する際にはアルゴリズムによる意思決定プロセスについて説明しなければならないということです。しかし何をもって説明とするかはまだ明確ではありません。例えば、最近傍分類器を使って到達した判断は説明可能な判断と言えるのか、それともロジスティック回帰分類器の係数の方が良いのか。テラバイトのデータを使って数百万のパラメータを簡単に学習させるディープニューラルネットワークはどうか？機械学習に基づく意思決定の説明可能性に関する技術的な実装についての議論は、現在集中的に行われています。いずれにせよ、GDPRはAI技術の透明性を向上させる可能性を持っています。

## 2. 百聞は一見にしかずは本当か？
![一見](./6_5-eyes.svg)

私たちは、見たものを信じることに慣れています。テレビで指導者が自国が他国と貿易戦争を行うと発言しているのを見たり、有名企業の広報担当者が重要なビジネス上の決定を発表したりすると、その発言について誰かが書いたニュースから二次的に読むよりも、その人を信用する傾向があります。

同様に、犯罪現場や新しいハイテク機器のデモンストレーションで証拠写真を見たとき、私たちは物事の見え方を説明したレポートよりも、その証拠を重視するのです。

もちろん、証拠が捏造される可能性があることは承知しています。写真加工によって、行ったこともない場所、会ったこともない人と一緒にいるように見せかけることができます。また、最新のダイエット薬の宣伝のための安っぽいビフォーアフター写真のように、照明を調整したりお腹を引っ込めたりするだけで物事の見え方を変えることも可能です。

> **Note** AIは証拠捏造の可能性を全く新しいレベルに引き上げつつある
>
>[Face2Face](https://www.youtube.com/watch?v=ohmajJTcpNk) は、ある人物の表情を識別し、それをYoutubeの動画内の別の人物の顔に合成することができるシステムです。
>
>[Lyrebird](https://www.descript.com/overdub?lyrebird=true) は、数分間のサンプル録音から人の声を自動で模倣するツールです。生成された音声はまだロボット調が目立つものの、かなり良い印象を与えることができます。

## 3. プライバシーの概念の変化
![監視カメラ](./6_6-camera.svg)

テクノロジー企業がユーザーに関する情報を大量に収集していることは以前から知られていました。それ以前は主に食料品店やその他の小売業者が店舗が個々の顧客と購入品を関連付けることができるポイントカードを顧客に渡すことによって購入データを収集していました。

> **Note** 前代未聞のデータ精度
>
>フェイスブック、グーグル、アマゾンなどのハイテク企業が収集するデータの精度は、従来の店舗が収集する購買データをはるかに超えています。原理的には、すべてのクリック、すべてのページスクロール、あらゆるコンテンツの閲覧時間を記録することが可能です。ウェブサイトは閲覧履歴にもアクセスできるので、あるサイトでバルセロナ行きの航空券を閲覧した後、シークレットモードなどを使用しない限り、バルセロナのホテルの広告が表示される可能性が高いのです。しかし、このように上記のようなデータロガーはまだAIではありません。AIの利用は、私たちのプライバシーに対する新たな脅威を招き、たとえ身元を明かすことに慎重であったとしても、それを避けることは難しいかもしれません。

## データ分析による個人特定
回避しにくい問題の好例は、安全だと思っていたデータの匿名性を破る非匿名化です。基本的な問題は、分析結果を報告する際にその結果が非常に具体的であるために分析に含まれるデータの個々のユーザーについて何かを知ることが可能になる場合があることです。典型的な例は、ある年に生まれ、特定の郵便番号を持つ人々の平均給与を求める分析などです。この場合、非常に小さなグループになることが多く、さらには一人しかいないことが多いので、一人の人間の給料に関するデータを提供することと同等になる可能性があります。

もっと微妙な問題については、テキサス大学オースティン校の研究者が興味深い例を指摘しています。彼らは、Netflixが公開している、約50万人の匿名ユーザーによる1000万件の映画評価を含むデータセットを研究し、Netflixユーザーの多くが、両方のアプリケーションで複数の映画を評価していたため、実際にはInternet Movie Databaseのユーザーアカウントとリンクできることを示しました。このように、研究者はNetflixのデータを非匿名化することができました。スター・ウォーズの最新作をどう評価したかを他人に知られるのは大したことではないと思うかもしれませんが、映画によっては、私たちが非公開にすべき生活（政治や性癖など）の側面が明らかになる場合があります。

## その他の識別方法
同様の手法は、原理的にはユーザーの行動に関する詳細なデータを収集するほとんどすべてのサービスにおいて、ユーザーアカウントの照合に使用することができます。もう一つの例は、タイピングパターンです。ヘルシンキ大学の研究者は、タイピングパターン（テキストを入力する際の特定のキーストロークの短い間隔）に基づいてユーザーを識別できることを実証しています。このことは、もし誰かがあなたのタイピングパターンのデータにアクセスできれば（おそらくあなたがウェブサイトを利用し、名前を入力して登録した場合）、あなたが明示的に身元を明かすことを拒否したとしても、次にそのサービスを利用するときにあなたを特定できることを意味します。また、この情報を買いたい人に売ることもできます。

上記の例の多くは想定外の驚きであり、問題に対処しようとする多くの研究が現在進行中です。特に、差分プライバシーと呼ばれる分野では、機械学習アルゴリズムの開発を目指しており、その結果に含まれる特定のデータポイントのリバースエンジニアリングを防ぐために、結果が十分に粗いことを保証できるようになっています。

## 4. 作業の変更
![ノートパソコンで作業するロボット](./6_7-robotWithLaptop.svg)

初期の人類が、死んだ動物の骨を鋭い石で割って新しい栄養源にアクセスすることを覚えたとき、時間とエネルギーは、戦いや仲間探し、さらなる発明をするなどの他の目的のために解放されました。1700年代に発明された蒸気機関は、簡単に持ち運べる機械動力であり、工場や船舶、鉄道の効率を大幅に向上させました。オートメーションは常に効率化への道であり、より少ない労力でより多くのものを得るための手段でした。特に20世紀半ば以降、技術開発によって自動化はかつてないほどの進歩を遂げました。AIはこの進歩の延長線上にあります。

より良い自動化への一歩一歩が労働生活を変えていきます。鋭い岩があれば狩猟や食料収集の必要性が減り、蒸気機関があれば馬や騎兵の必要性が減り、コンピューターがあればタイピストや手作業の会計、その他多くのデータ処理の必要性が減ります（そして明らかに猫のビデオを見る必要性は増えます）。AIとロボット工学のおかげで多くの種類の退屈な反復作業がさらに少なくなっています。

> **Note** 新しいものを見つけてきた歴史
>
>これまである種の仕事が自動化されるたびに、人々はそれに代わる新たな仕事を見出してきました。新しい仕事は、反復的・定型的でなく、より変化に富み、より創造的になりました。現在のAIなどの技術の進歩の速さの問題は、個人のキャリアの中で労働生活の変化がこれまで以上に大きくなる可能性があることです。トラックやタクシーの運転手など数年のタイムスパンで消滅する仕事も考えられます。このような急激な変化は、人々が他の種類の仕事のために訓練する時間がないため、大量失業につながる可能性があります。
>
>このような社会的な大問題を回避するために最も重要なことは、若い人たちが幅広い教育を受けられるようにすることです。そのためには、さまざまな仕事をするための基礎となる近い将来に陳腐化する恐れのない幅広い教育を受けることが必要です。
>
>また、生涯を通じて同じ仕事をする人はほとんどいないでしょうから、生涯学習や仕事での学びを支援することも同様に重要です。週当たりの労働時間を減らせば、より多くの人に仕事を提供することができますが、経済学の法則では労働量を規制する公共政策が導入されない限り、人々はむしろより多く働くようになる傾向があります。

AIの未来は予測できないので、この発展の速度と程度を予測することは非常に難しいです。仕事の自動化がどの程度進むかについては、オックスフォード大学の研究者が報告した、米国の仕事の47％がリスクにさらされるという試算もあります。45％や49％ではなく47％という正確な数字、それを得るための複雑な研究デザイン、そしてそれを報告する一流大学によって、この推計は非常に信頼性が高く、正確に聞こえる傾向があります（限られたデータに基づいて線形モデルを使用して平均寿命を推定する際のポイントを思い出してみましょう）。1パーセントの正確さの錯覚は誤りです。例えば上記の数字は、多数の職務内容の中からおそらく指先を舐めて風を感じながら主観的な根拠でどの業務が自動化されそうかを判断したものでしょう。「タスクモデルは、扱いやすさを考慮して集約的で規模に応じた一定のリターンを持つコブ・ダグラス生産関数を仮定している」などと書かれた79ページの報告書を多くの人はわざわざ読まないでしょう。しかし、そうならば、結論についても多少は懐疑的であるべきでしょう。この種の分析の真価は、47%という実際の数字ではなく、どのような種類の仕事がよりリスクにさらされる可能性が高いかを示唆することにあります。悲劇は「米国の仕事の半分近くがコンピューター化のリスクにさらされている」と報じる見出しが記憶され、それ以外は記憶されないということです。

では自動化される可能性が高い業務とは何でしょうか。これについてはすでにいくつかの明確な兆候が見られます。

- 自動車、ドローン、ボートやフェリーなどの自動運転のような自律型ロボティクス・ソリューションは、主要な商用サービスを提供する手前まで来ています。自律走行車の安全性を評価するのは難しいですが、統計によるとおそらくまだ必要なレベル（平均的な人間ドライバーのレベル）には達していないようです。しかし、その進歩は信じられないほど速く、利用可能なデータの量が増えているため、加速しています。

- ヘルプデスクなどの顧客サービスは非常に費用対効果の高い方法で自動化することができます。現在のところ、サービスの質は必ずしも褒められたものではなく、ボトルネックは言語処理（システムが話し言葉を認識できない、あるいは文法を解析できない）と実際のサービスを提供するのに必要な論理と推論能力の不足にあります。しかし、レストランや散髪の予約など制約の多い領域での実用的なサービスは次々と生まれています。

ひとつには、安全で信頼性の高い自動運転車など、人間の仕事を代替できるソリューションがいつ実現されるのかわからないということが挙げられます。さらに、トラックやタクシーの運転手は、ただハンドルを回すだけでなく、車両が正常に作動するかどうか、荷物の取り扱いや顧客との交渉、荷物や乗客の安全保証など、実際の運転よりもはるかに自動化が困難と思われる多数の仕事を受け持っていることを忘れてはいけません。

また、以前の技術の進歩と同様に、AIがあるからこそ生まれる新しい仕事もあるでしょう。将来的には、研究開発や創造性や人間と人間の相互作用が必要な業務に、労働力のより多くの割合が集中することになると思われます。このテーマについてもっと読みたい方は、例えばAbhinav Suriの[「Artificial Intelligence and the Rise of Economic Inequality(人工知能と経済格差の台頭)」](https://towardsdatascience.com/artificial-intelligence-and-the-rise-of-economic-inequality-b9d81be58bec)という素晴らしいエッセイを参照してください。

## 設問 24: AIの意味するところ

新聞や雑誌、あるいはブログなどの一般的な科学媒体において、AIについてどのような記事が書かれているか調べ、それは現実的なものだと思うかどうか感想を述べてください。自分の興味に関連するAIについての記事をオンライン検索して探してみてください。その記事の中から一つを選び、分析して、下記についてレポートしてください。

1. 記事のタイトル、著者名、URL
2. 記事の中心的な考え方を、1段落程度の文章で自分の言葉で説明してください。
3. あなたの理解では、この記事のAIに関する記述はどの程度正確ですか？その答えを説明してください。その意味するところは現実的ですか？その理由を説明してください。